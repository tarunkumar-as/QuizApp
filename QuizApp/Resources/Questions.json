[
  {
    "Primary_Index": 1,
    "Categorie_Id": 1,
    "Categorie": "AL/ML",
    "Course_Id": 1,
    "Course": "Data Science",
    "Section_Id": 1,
    "Section": "Linear Regression",
    "Difficulty_Id": 2,
    "Difficulty": "Medium",
    "Question_Id": 1,
    "Question": "How adding a new variable to the model will affect the adjusted R square ?",
    "Option_1 ": "Increase the Value",
    "Option_2 ": "Decrease the value",
    "Option_3 ": "Depends on the variable contribution",
    "Option_4 ": "No affect ",
    "Correct_Answer": "Depends on the variable contribution",
    "Correct_Option": 3,
    "Short_Description": "The adjusted R-squared compares the descriptive power of regression models—two or more variables—that include a diverse number of independent variables—known as a predictor",
    "Detailed_Description": "The Adjusted R-squared value is similar to the Multiple R-squared value,\nbut it accounts for the number of variables. This means that the Multiple R-squared will always increase\nwhen a new variable is added to the prediction model, but if the variable is a non-significant one, the Adjusted R-squared value will decrease.",
    "Reference_Link": "https://www.investopedia.com/ask/answers/012615/whats-difference-between-rsquared-and-adjusted-rsquared.asp#targetText=One%20major%20difference%20between%20R,variation%20in%20the%20dependent%20variable.&targetText=The%20adjusted%20R%2Dsquared%20is,of%20predictors%20in%20a%20model."
  },
  {
    "Primary_Index": 2,
    "Categorie_Id": 1,
    "Categorie": "AL/ML",
    "Course_Id": 1,
    "Course": "Data Science",
    "Section_Id": 1,
    "Section": "Linear Regression",
    "Difficulty_Id": 2,
    "Difficulty": "Medium",
    "Question_Id": 2,
    "Question": "How adding a new variable to the model will affect the R square ?",
    "Option_1 ": "Increase the Value",
    "Option_2 ": "Decrease the value",
    "Option_3 ": "Depends on the variable contribution",
    "Option_4 ": "No affect ",
    "Correct_Answer": "Increase the Value",
    "Correct_Option": 1,
    "Short_Description": "R2 assumes every independent variable in the model explains the variation in the dependent variable.",
    "Detailed_Description": " R2 explains the degree to which your input variables explain the variation of your output / predicted variable. So, if R-square is 0.8, it means 80% of the variation in the output variable is explained by the input variables. So, in simple terms, higher the R squared, the more variation is explained by your input variables and hence better is your model.\n\nR-squared = 1 – SSE/SST where:\nSSE is the sum of square of residuals. Residual is the difference between the predicted value and the actual value, and can be accessed by predictionModel$residuals.\nSST is the total sum of squares. It is calculated by summing the squares of difference between the actual value and the mean value.",
    "Reference_Link": "https://www.investopedia.com/ask/answers/012615/whats-difference-between-rsquared-and-adjusted-rsquared.asp#targetText=One%20major%20difference%20between%20R,variation%20in%20the%20dependent%20variable.&targetText=The%20adjusted%20R%2Dsquared%20is,of%20predictors%20in%20a%20model."
  },
  {
    "Primary_Index": 3,
    "Categorie_Id": 1,
    "Categorie": "AL/ML",
    "Course_Id": 1,
    "Course": "Data Science",
    "Section_Id": 1,
    "Section": "Logistic Regression",
    "Difficulty_Id": 1,
    "Difficulty": "Easy",
    "Question_Id": 3,
    "Question": "What is the area under the ROC curve ?",
    "Option_1 ": "1",
    "Option_2 ": "0",
    "Option_3 ": "Scale Invariant",
    "Option_4 ": "-Infinite to + Infinite",
    "Correct_Answer": "1",
    "Correct_Option": 1,
    "Short_Description": " A test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100% sensitivity, 100% specificity).",
    "Detailed_Description": "In a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold. The closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test (Zweig & Campbell, 1993).",
    "Reference_Link": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
  }
]
